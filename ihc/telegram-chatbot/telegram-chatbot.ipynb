{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XlJrsR89_jb6"
      },
      "source": [
        "# Instalações das bibliotecas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "9sWGWwgcSaXq",
        "outputId": "88f4de68-fc95-49b8-ab78-19c6b1d72ca9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: python-telegram-bot==13.7 in c:\\users\\danie\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (13.7)\n",
            "Requirement already satisfied: certifi in c:\\users\\danie\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from python-telegram-bot==13.7) (2023.7.22)\n",
            "Requirement already satisfied: tornado>=6.1 in c:\\users\\danie\\appdata\\roaming\\python\\python311\\site-packages (from python-telegram-bot==13.7) (6.3.3)\n",
            "Requirement already satisfied: APScheduler==3.6.3 in c:\\users\\danie\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from python-telegram-bot==13.7) (3.6.3)\n",
            "Requirement already satisfied: pytz>=2018.6 in c:\\users\\danie\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from python-telegram-bot==13.7) (2023.3.post1)\n",
            "Requirement already satisfied: cachetools==4.2.2 in c:\\users\\danie\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from python-telegram-bot==13.7) (4.2.2)\n",
            "Requirement already satisfied: setuptools>=0.7 in c:\\users\\danie\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from APScheduler==3.6.3->python-telegram-bot==13.7) (68.2.2)\n",
            "Requirement already satisfied: six>=1.4.0 in c:\\users\\danie\\appdata\\roaming\\python\\python311\\site-packages (from APScheduler==3.6.3->python-telegram-bot==13.7) (1.16.0)\n",
            "Requirement already satisfied: tzlocal>=1.2 in c:\\users\\danie\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from APScheduler==3.6.3->python-telegram-bot==13.7) (5.2)\n",
            "Requirement already satisfied: tzdata in c:\\users\\danie\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tzlocal>=1.2->APScheduler==3.6.3->python-telegram-bot==13.7) (2023.3)\n",
            "Requirement already satisfied: llama_cpp_python in c:\\users\\danie\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (0.2.64)\n",
            "Requirement already satisfied: typing-extensions>=4.5.0 in c:\\users\\danie\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from llama_cpp_python) (4.9.0)\n",
            "Requirement already satisfied: numpy>=1.20.0 in c:\\users\\danie\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from llama_cpp_python) (1.26.0)\n",
            "Requirement already satisfied: diskcache>=5.6.1 in c:\\users\\danie\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from llama_cpp_python) (5.6.3)\n",
            "Requirement already satisfied: jinja2>=2.11.3 in c:\\users\\danie\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from llama_cpp_python) (3.1.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\danie\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from jinja2>=2.11.3->llama_cpp_python) (2.1.3)\n",
            "Requirement already satisfied: pytelegrambotapi in c:\\users\\danie\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (4.17.0)\n",
            "Requirement already satisfied: requests in c:\\users\\danie\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pytelegrambotapi) (2.31.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\danie\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->pytelegrambotapi) (3.3.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\danie\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->pytelegrambotapi) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\danie\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->pytelegrambotapi) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\danie\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->pytelegrambotapi) (2023.7.22)\n"
          ]
        }
      ],
      "source": [
        "!pip install python-telegram-bot==13.7\n",
        "!pip install llama_cpp_python\n",
        "!pip install pytelegrambotapi"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v_05IcrG81yG"
      },
      "source": [
        "# LLama (Inteligência Artificial)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d0nQsxyU8yeU"
      },
      "source": [
        "Configuração da IA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\danie\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n",
            "You set `add_prefix_space`. The tokenizer needs to be converted from the slow tokenizers\n",
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
            "llama_model_loader: loaded meta data with 25 key-value pairs and 291 tensors from C:\\Users\\danie\\.cache\\huggingface\\hub\\models--meetkai--functionary-small-v2.4-GGUF\\snapshots\\a0d171eb78e02a58858c464e278234afbcf85c5c\\.\\functionary-small-v2.4.Q4_0.gguf (version GGUF V3 (latest))\n",
            "llama_model_loader: Dumping metadata keys/values. Note: KV overrides do not apply in this output.\n",
            "llama_model_loader: - kv   0:                       general.architecture str              = llama\n",
            "llama_model_loader: - kv   1:                               general.name str              = .\n",
            "llama_model_loader: - kv   2:                           llama.vocab_size u32              = 32004\n",
            "llama_model_loader: - kv   3:                       llama.context_length u32              = 32768\n",
            "llama_model_loader: - kv   4:                     llama.embedding_length u32              = 4096\n",
            "llama_model_loader: - kv   5:                          llama.block_count u32              = 32\n",
            "llama_model_loader: - kv   6:                  llama.feed_forward_length u32              = 14336\n",
            "llama_model_loader: - kv   7:                 llama.rope.dimension_count u32              = 128\n",
            "llama_model_loader: - kv   8:                 llama.attention.head_count u32              = 32\n",
            "llama_model_loader: - kv   9:              llama.attention.head_count_kv u32              = 8\n",
            "llama_model_loader: - kv  10:     llama.attention.layer_norm_rms_epsilon f32              = 0.000010\n",
            "llama_model_loader: - kv  11:                       llama.rope.freq_base f32              = 1000000.000000\n",
            "llama_model_loader: - kv  12:                          general.file_type u32              = 2\n",
            "llama_model_loader: - kv  13:                       tokenizer.ggml.model str              = llama\n",
            "llama_model_loader: - kv  14:                      tokenizer.ggml.tokens arr[str,32004]   = [\"<unk>\", \"<s>\", \"</s>\", \"<0x00>\", \"<...\n",
            "llama_model_loader: - kv  15:                      tokenizer.ggml.scores arr[f32,32004]   = [0.000000, 0.000000, 0.000000, 0.0000...\n",
            "llama_model_loader: - kv  16:                  tokenizer.ggml.token_type arr[i32,32004]   = [2, 3, 3, 6, 6, 6, 6, 6, 6, 6, 6, 6, ...\n",
            "llama_model_loader: - kv  17:                tokenizer.ggml.bos_token_id u32              = 1\n",
            "llama_model_loader: - kv  18:                tokenizer.ggml.eos_token_id u32              = 2\n",
            "llama_model_loader: - kv  19:            tokenizer.ggml.unknown_token_id u32              = 0\n",
            "llama_model_loader: - kv  20:            tokenizer.ggml.padding_token_id u32              = 2\n",
            "llama_model_loader: - kv  21:               tokenizer.ggml.add_bos_token bool             = true\n",
            "llama_model_loader: - kv  22:               tokenizer.ggml.add_eos_token bool             = false\n",
            "llama_model_loader: - kv  23:                    tokenizer.chat_template str              = {% for message in messages %}\\n{% if m...\n",
            "llama_model_loader: - kv  24:               general.quantization_version u32              = 2\n",
            "llama_model_loader: - type  f32:   65 tensors\n",
            "llama_model_loader: - type q4_0:  225 tensors\n",
            "llama_model_loader: - type q6_K:    1 tensors\n",
            "llm_load_vocab: special tokens definition check successful ( 263/32004 ).\n",
            "llm_load_print_meta: format           = GGUF V3 (latest)\n",
            "llm_load_print_meta: arch             = llama\n",
            "llm_load_print_meta: vocab type       = SPM\n",
            "llm_load_print_meta: n_vocab          = 32004\n",
            "llm_load_print_meta: n_merges         = 0\n",
            "llm_load_print_meta: n_ctx_train      = 32768\n",
            "llm_load_print_meta: n_embd           = 4096\n",
            "llm_load_print_meta: n_head           = 32\n",
            "llm_load_print_meta: n_head_kv        = 8\n",
            "llm_load_print_meta: n_layer          = 32\n",
            "llm_load_print_meta: n_rot            = 128\n",
            "llm_load_print_meta: n_embd_head_k    = 128\n",
            "llm_load_print_meta: n_embd_head_v    = 128\n",
            "llm_load_print_meta: n_gqa            = 4\n",
            "llm_load_print_meta: n_embd_k_gqa     = 1024\n",
            "llm_load_print_meta: n_embd_v_gqa     = 1024\n",
            "llm_load_print_meta: f_norm_eps       = 0.0e+00\n",
            "llm_load_print_meta: f_norm_rms_eps   = 1.0e-05\n",
            "llm_load_print_meta: f_clamp_kqv      = 0.0e+00\n",
            "llm_load_print_meta: f_max_alibi_bias = 0.0e+00\n",
            "llm_load_print_meta: f_logit_scale    = 0.0e+00\n",
            "llm_load_print_meta: n_ff             = 14336\n",
            "llm_load_print_meta: n_expert         = 0\n",
            "llm_load_print_meta: n_expert_used    = 0\n",
            "llm_load_print_meta: causal attn      = 1\n",
            "llm_load_print_meta: pooling type     = 0\n",
            "llm_load_print_meta: rope type        = 0\n",
            "llm_load_print_meta: rope scaling     = linear\n",
            "llm_load_print_meta: freq_base_train  = 1000000.0\n",
            "llm_load_print_meta: freq_scale_train = 1\n",
            "llm_load_print_meta: n_yarn_orig_ctx  = 32768\n",
            "llm_load_print_meta: rope_finetuned   = unknown\n",
            "llm_load_print_meta: ssm_d_conv       = 0\n",
            "llm_load_print_meta: ssm_d_inner      = 0\n",
            "llm_load_print_meta: ssm_d_state      = 0\n",
            "llm_load_print_meta: ssm_dt_rank      = 0\n",
            "llm_load_print_meta: model type       = 8B\n",
            "llm_load_print_meta: model ftype      = Q4_0\n",
            "llm_load_print_meta: model params     = 7.24 B\n",
            "llm_load_print_meta: model size       = 3.83 GiB (4.54 BPW) \n",
            "llm_load_print_meta: general.name     = .\n",
            "llm_load_print_meta: BOS token        = 1 '<s>'\n",
            "llm_load_print_meta: EOS token        = 2 '</s>'\n",
            "llm_load_print_meta: UNK token        = 0 '<unk>'\n",
            "llm_load_print_meta: PAD token        = 2 '</s>'\n",
            "llm_load_print_meta: LF token         = 13 '<0x0A>'\n",
            "llm_load_tensors: ggml ctx size =    0.15 MiB\n",
            "llm_load_tensors:        CPU buffer size =  3917.89 MiB\n",
            "..................................................................................................\n",
            "llama_new_context_with_model: n_ctx      = 512\n",
            "llama_new_context_with_model: n_batch    = 512\n",
            "llama_new_context_with_model: n_ubatch   = 512\n",
            "llama_new_context_with_model: freq_base  = 1000000.0\n",
            "llama_new_context_with_model: freq_scale = 1\n",
            "llama_kv_cache_init:        CPU KV buffer size =    64.00 MiB\n",
            "llama_new_context_with_model: KV self size  =   64.00 MiB, K (f16):   32.00 MiB, V (f16):   32.00 MiB\n",
            "llama_new_context_with_model:        CPU  output buffer size =     0.12 MiB\n",
            "llama_new_context_with_model:        CPU compute buffer size =    81.01 MiB\n",
            "llama_new_context_with_model: graph nodes  = 1030\n",
            "llama_new_context_with_model: graph splits = 1\n",
            "AVX = 1 | AVX_VNNI = 0 | AVX2 = 1 | AVX512 = 0 | AVX512_VBMI = 0 | AVX512_VNNI = 0 | FMA = 1 | NEON = 0 | ARM_FMA = 0 | F16C = 1 | FP16_VA = 0 | WASM_SIMD = 0 | BLAS = 0 | SSE3 = 1 | SSSE3 = 0 | VSX = 0 | MATMUL_INT8 = 0 | \n",
            "Model metadata: {'general.name': '.', 'general.architecture': 'llama', 'llama.block_count': '32', 'llama.vocab_size': '32004', 'llama.context_length': '32768', 'llama.rope.dimension_count': '128', 'llama.embedding_length': '4096', 'llama.feed_forward_length': '14336', 'llama.attention.head_count': '32', 'tokenizer.ggml.eos_token_id': '2', 'general.file_type': '2', 'llama.attention.head_count_kv': '8', 'llama.attention.layer_norm_rms_epsilon': '0.000010', 'llama.rope.freq_base': '1000000.000000', 'tokenizer.ggml.model': 'llama', 'general.quantization_version': '2', 'tokenizer.ggml.bos_token_id': '1', 'tokenizer.ggml.unknown_token_id': '0', 'tokenizer.ggml.padding_token_id': '2', 'tokenizer.ggml.add_bos_token': 'true', 'tokenizer.ggml.add_eos_token': 'false', 'tokenizer.chat_template': '{% for message in messages %}\\n{% if message[\\'role\\'] == \\'user\\' or message[\\'role\\'] == \\'system\\' %}\\n{{ \\'<|from|>\\' + message[\\'role\\'] + \\'\\n<|recipient|>all\\n<|content|>\\' + message[\\'content\\'] + \\'\\n\\' }}{% elif message[\\'role\\'] == \\'tool\\' %}\\n{{ \\'<|from|>\\' + message[\\'name\\'] + \\'\\n<|recipient|>all\\n<|content|>\\' + message[\\'content\\'] + \\'\\n\\' }}{% else %}\\n{% set contain_content=\\'no\\'%}\\n{% if message[\\'content\\'] is not none %}\\n{{ \\'<|from|>assistant\\n<|recipient|>all\\n<|content|>\\' + message[\\'content\\'] }}{% set contain_content=\\'yes\\'%}\\n{% endif %}\\n{% if \\'tool_calls\\' in message and message[\\'tool_calls\\'] is not none %}\\n{% for tool_call in message[\\'tool_calls\\'] %}\\n{% set prompt=\\'<|from|>assistant\\n<|recipient|>\\' + tool_call[\\'function\\'][\\'name\\'] + \\'\\n<|content|>\\' + tool_call[\\'function\\'][\\'arguments\\'] %}\\n{% if loop.index == 1 and contain_content == \"no\" %}\\n{{ prompt }}{% else %}\\n{{ \\'\\n\\' + prompt}}{% endif %}\\n{% endfor %}\\n{% endif %}\\n{{ \\'<|stop|>\\n\\' }}{% endif %}\\n{% endfor %}\\n{% if add_generation_prompt %}{{ \\'<|from|>assistant\\n<|recipient|>\\' }}{% endif %}'}\n"
          ]
        }
      ],
      "source": [
        "from llama_cpp import Llama\n",
        "from llama_cpp.llama_tokenizer import LlamaHFTokenizer\n",
        "\n",
        "llm = Llama.from_pretrained(\n",
        "    repo_id=\"meetkai/functionary-small-v2.4-GGUF\",\n",
        "    filename=\"functionary-small-v2.4.Q4_0.gguf\",\n",
        "    chat_format=\"functionary-v2\",\n",
        "    tokenizer=LlamaHFTokenizer.from_pretrained(\"meetkai/functionary-small-v2.4-GGUF\"),\n",
        "    n_gpu_layers=-1,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5mjZCkhT7Sku"
      },
      "source": [
        "# Funções do Chatbot"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DIoWL6p66WyS"
      },
      "source": [
        "Definindo as funções"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "PxFGa3Cz6UT7"
      },
      "outputs": [],
      "source": [
        "import sqlite3\n",
        "\n",
        "# Funções\n",
        "def greet_user():\n",
        "    return \"Olá! Como posso ajudar você hoje?\"\n",
        "\n",
        "def search_books(name):\n",
        "    conn = sqlite3.connect('bookstore.db', timeout=10)\n",
        "    cursor = conn.cursor()\n",
        "    \n",
        "    query = \"SELECT title FROM books WHERE title LIKE ?\"\n",
        "    cursor.execute(query, ('%' + name + '%',))\n",
        "    books = cursor.fetchall()\n",
        "    \n",
        "    conn.close()\n",
        "    \n",
        "    if books:\n",
        "        return \"Livros encontrados:\\n\" + \"\\n\".join(f\"* {book[0]}\" for book in books)\n",
        "    else:\n",
        "        return \"Nenhum livro encontrado com esse nome.\"\n",
        "\n",
        "# Estrutura para armazenar o carrinho\n",
        "cart = []\n",
        "\n",
        "def add_to_cart(book_title):\n",
        "    conn = sqlite3.connect('bookstore.db', timeout=10)\n",
        "    cursor = conn.cursor()\n",
        "    \n",
        "    query = \"SELECT title, price FROM books WHERE title = ?\"\n",
        "    cursor.execute(query, (book_title,))\n",
        "    book = cursor.fetchone()\n",
        "    \n",
        "    conn.close()\n",
        "    \n",
        "    if book:\n",
        "        cart.append(book)\n",
        "        return f\"{book_title} foi adicionado ao seu carrinho.\"\n",
        "    else:\n",
        "        return \"Livro não encontrado.\"\n",
        "\n",
        "def remove_from_cart(book_title):\n",
        "    for book in cart:\n",
        "        if book[0] == book_title:\n",
        "            cart.remove(book)\n",
        "            return f\"{book_title} foi removido do seu carrinho.\"\n",
        "    return \"Livro não encontrado no seu carrinho.\"\n",
        "\n",
        "def view_cart():\n",
        "    if cart:\n",
        "        total = sum(book[1] for book in cart)\n",
        "        books_in_cart = \"\\n\".join(f\"* {book[0]} - R${book[1]:.2f}\" for book in cart)\n",
        "        return f\"Livros no seu carrinho:\\n{books_in_cart}\\n\\nTotal: R${total:.2f}\"\n",
        "    else:\n",
        "        return \"Seu carrinho está vazio.\"\n",
        "\n",
        "def checkout():\n",
        "    if cart:\n",
        "        total = sum(book[1] for book in cart)\n",
        "        cart.clear()  # Esvaziar o carrinho após a compra\n",
        "        return f\"Sua compra foi finalizada com sucesso. Total: R${total:.2f}\"\n",
        "    else:\n",
        "        return \"Seu carrinho está vazio.\"\n",
        "\n",
        "def get_author_by_book_title(book_title):\n",
        "    conn = sqlite3.connect('bookstore.db', timeout=10)\n",
        "    cursor = conn.cursor()\n",
        "    \n",
        "    query = '''\n",
        "        SELECT authors.name \n",
        "        FROM books \n",
        "        JOIN authors ON books.author_id = authors.id \n",
        "        WHERE books.title = ?\n",
        "    '''\n",
        "    cursor.execute(query, (book_title,))\n",
        "    author = cursor.fetchone()\n",
        "    \n",
        "    conn.close()\n",
        "    \n",
        "    if author:\n",
        "        return f\"O autor do livro '{book_title}' é {author[0]}.\"\n",
        "    else:\n",
        "        return \"Autor não encontrado para esse livro.\"\n",
        "\n",
        "# Mapeamento das funções\n",
        "functions_map = {\n",
        "    \"greet_user\": greet_user,\n",
        "    \"search_books\": search_books,\n",
        "    \"add_to_cart\": add_to_cart,\n",
        "    \"remove_from_cart\": remove_from_cart,\n",
        "    \"view_cart\": view_cart,\n",
        "    \"checkout\": checkout,\n",
        "    \"get_author_by_book_title\": get_author_by_book_title,\n",
        "}\n",
        "\n",
        "# Ferramentas do chatbot\n",
        "tools = [\n",
        "    {\n",
        "        \"type\": \"function\",\n",
        "        \"function\": {\n",
        "            \"name\": \"search_books\",\n",
        "            \"description\": \"Search for a specific book\",\n",
        "            \"parameters\": {\n",
        "                \"type\": \"object\",\n",
        "                \"properties\": {\"name\": {\"type\": \"string\", \"description\": \"The name of the book\"}},\n",
        "                \"required\": [\"name\"],\n",
        "            },\n",
        "        },\n",
        "    },\n",
        "    {\n",
        "        \"type\": \"function\",\n",
        "        \"function\": {\n",
        "            \"name\": \"greet_user\",\n",
        "            \"description\": \"Greet the user and ask how to help\",\n",
        "            \"parameters\": {\n",
        "                \"type\": \"object\",\n",
        "                \"properties\": {},\n",
        "                \"required\": [],\n",
        "            },\n",
        "        },\n",
        "    },\n",
        "    {\n",
        "        \"type\": \"function\",\n",
        "        \"function\": {\n",
        "            \"name\": \"add_to_cart\",\n",
        "            \"description\": \"Add a book to the cart\",\n",
        "            \"parameters\": {\n",
        "                \"type\": \"object\",\n",
        "                \"properties\": {\n",
        "                    \"book_title\": {\"type\": \"string\", \"description\": \"The title of the book to add\"},\n",
        "                },\n",
        "                \"required\": [\"book_title\"],\n",
        "            },\n",
        "        },\n",
        "    },\n",
        "    {\n",
        "        \"type\": \"function\",\n",
        "        \"function\": {\n",
        "            \"name\": \"remove_from_cart\",\n",
        "            \"description\": \"Remove a book from the cart\",\n",
        "            \"parameters\": {\n",
        "                \"type\": \"object\",\n",
        "                \"properties\": {\n",
        "                    \"book_title\": {\"type\": \"string\", \"description\": \"The title of the book to remove\"},\n",
        "                },\n",
        "                \"required\": [\"book_title\"],\n",
        "            },\n",
        "        },\n",
        "    },\n",
        "    {\n",
        "        \"type\": \"function\",\n",
        "        \"function\": {\n",
        "            \"name\": \"view_cart\",\n",
        "            \"description\": \"View the prices of books in the cart and the total amount\",\n",
        "            \"parameters\": {\n",
        "                \"type\": \"object\",\n",
        "                \"properties\": {},\n",
        "                \"required\": [],\n",
        "            },\n",
        "        },\n",
        "    },\n",
        "    {\n",
        "        \"type\": \"function\",\n",
        "        \"function\": {\n",
        "            \"name\": \"checkout\",\n",
        "            \"description\": \"Checkout and finalize the purchase\",\n",
        "            \"parameters\": {\n",
        "                \"type\": \"object\",\n",
        "                \"properties\": {},\n",
        "                \"required\": [],\n",
        "            },\n",
        "        },\n",
        "    },\n",
        "    {\n",
        "        \"type\": \"function\",\n",
        "        \"function\": {\n",
        "            \"name\": \"get_author_by_book_title\",\n",
        "            \"description\": \"Get the author of a specific book\",\n",
        "            \"parameters\": {\n",
        "                \"type\": \"object\",\n",
        "                \"properties\": {\n",
        "                    \"book_title\": {\"type\": \"string\", \"description\": \"The title of the book\"},\n",
        "                },\n",
        "                \"required\": [\"book_title\"],\n",
        "            },\n",
        "        },\n",
        "    },\n",
        "]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2AggLIjh7mx1"
      },
      "source": [
        "# Banco SQLite"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l2La_4KETBZ9"
      },
      "source": [
        "Configuração do Banco SQLite"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "tdsjcgz1SxE1"
      },
      "outputs": [],
      "source": [
        "import sqlite3\n",
        "\n",
        "conn = sqlite3.connect('bookstore.db', timeout=10)\n",
        "cursor = conn.cursor()\n",
        "\n",
        "cursor.execute('DROP TABLE IF EXISTS books')\n",
        "cursor.execute('DROP TABLE IF EXISTS authors')\n",
        "\n",
        "# Criando a tabela authors\n",
        "cursor.execute('''\n",
        "CREATE TABLE IF NOT EXISTS authors (\n",
        "    id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
        "    name TEXT NOT NULL\n",
        ")\n",
        "''')\n",
        "\n",
        "# Criando a tabela books\n",
        "cursor.execute('''\n",
        "CREATE TABLE IF NOT EXISTS books (\n",
        "    id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
        "    title TEXT NOT NULL,\n",
        "    author_id INTEGER,\n",
        "    price REAL,\n",
        "    FOREIGN KEY (author_id) REFERENCES authors (id)\n",
        ")\n",
        "''')\n",
        "\n",
        "# Inserindo autores\n",
        "authors = [('J.K. Rowling',), ('J.R.R. Tolkien',), ('George Orwell',)]\n",
        "cursor.executemany('INSERT INTO authors (name) VALUES (?)', authors)\n",
        "\n",
        "# Inserindo livros\n",
        "books = [\n",
        "    ('Harry Potter and the Philosopher\\'s Stone', 1, 19.99),\n",
        "    ('Harry Potter and the Chamber of Secrets', 1, 24.99),\n",
        "    ('The Hobbit', 2, 15.99),\n",
        "    ('1984', 3, 12.99),\n",
        "]\n",
        "cursor.executemany('INSERT INTO books (title, author_id, price) VALUES (?, ?, ?)', books)\n",
        "\n",
        "# Salvando (commit) as alterações e fechando a conexão\n",
        "conn.commit()\n",
        "conn.close()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CZpcxWeF9eut"
      },
      "source": [
        "# Chatbot"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Configuração do Chatbot"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [],
      "source": [
        "import telebot\n",
        "import json\n",
        "\n",
        "# Altere para o token do seu bot\n",
        "API_TOKEN = '7112544250:AAF7irmOrLAo92-Sb-jqAptH7zJM7pnBYLo'\n",
        "\n",
        "bot = telebot.TeleBot(API_TOKEN)\n",
        "\n",
        "def get_function_details(llm, message, tools):\n",
        "    result = llm.create_chat_completion(\n",
        "        messages=[{\"role\": \"user\", \"content\": message}],\n",
        "        tools=tools,\n",
        "        tool_choice=\"auto\",\n",
        "    )\n",
        "    function_call = result[\"choices\"][0][\"message\"][\"function_call\"]\n",
        "    function_name = function_call[\"name\"]\n",
        "    arguments = json.loads(function_call[\"arguments\"])\n",
        "    return function_name, arguments\n",
        "\n",
        "def execute_function(function_name, arguments, functions_map):\n",
        "    function = functions_map.get(function_name)\n",
        "    if function:\n",
        "        return function(**arguments)\n",
        "    return f\"Deculpe, eu não entendi o que você quis dizer.\"\n",
        "\n",
        "@bot.message_handler(func=lambda message: True)\n",
        "def reply_to_message(message):\n",
        "    function_name, arguments = get_function_details(llm, message.text, tools)\n",
        "    response = execute_function(function_name, arguments, functions_map)\n",
        "    bot.reply_to(message, response)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QG7Z697knwSw"
      },
      "source": [
        "Ativação do Chatbot"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "HwyIIUJvVPNQ"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =   89063.21 ms\n",
            "llama_print_timings:      sample time =       3.11 ms /    11 runs   (    0.28 ms per token,  3538.12 tokens per second)\n",
            "llama_print_timings: prompt eval time =   22934.22 ms /   120 tokens (  191.12 ms per token,     5.23 tokens per second)\n",
            "llama_print_timings:        eval time =    4077.69 ms /    10 runs   (  407.77 ms per token,     2.45 tokens per second)\n",
            "llama_print_timings:       total time =   27088.15 ms /   130 tokens\n",
            "from_string grammar:\n",
            "book-title-kv ::= [\"] [b] [o] [o] [k] [_] [t] [i] [t] [l] [e] [\"] space [:] space string \n",
            "space ::= space_6 \n",
            "string ::= [\"] string_7 [\"] space \n",
            "char ::= [^\"\\] | [\\] char_4 \n",
            "char_4 ::= [\"\\/bfnrt] | [u] [0-9a-fA-F] [0-9a-fA-F] [0-9a-fA-F] [0-9a-fA-F] \n",
            "root ::= [{] space book-title-kv [}] space \n",
            "space_6 ::= [ ] | \n",
            "string_7 ::= char string_7 | \n",
            "\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "book-title-kv ::= \"\\\"book_title\\\"\" space \":\" space string\n",
            "char ::= [^\"\\\\] | \"\\\\\" ([\"\\\\/bfnrt] | \"u\" [0-9a-fA-F] [0-9a-fA-F] [0-9a-fA-F] [0-9a-fA-F])\n",
            "root ::= \"{\" space book-title-kv \"}\" space\n",
            "space ::= \" \"?\n",
            "string ::= \"\\\"\" char* \"\\\"\" space\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "llama_print_timings:        load time =   89063.21 ms\n",
            "llama_print_timings:      sample time =     124.02 ms /    13 runs   (    9.54 ms per token,   104.82 tokens per second)\n",
            "llama_print_timings: prompt eval time =       0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_print_timings:        eval time =    5375.38 ms /    13 runs   (  413.49 ms per token,     2.42 tokens per second)\n",
            "llama_print_timings:       total time =    5599.52 ms /    14 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =   89063.21 ms\n",
            "llama_print_timings:      sample time =       0.28 ms /     1 runs   (    0.28 ms per token,  3546.10 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2213.24 ms /    11 tokens (  201.20 ms per token,     4.97 tokens per second)\n",
            "llama_print_timings:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_print_timings:       total time =    2219.94 ms /    12 tokens\n"
          ]
        }
      ],
      "source": [
        "\n",
        "bot.polling()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
